---
layout: student
esr: 14
name: Alessandro Piscopo
image: alessandro.jpg
project: How to Make a Good Collaborative Knowledge Graph: Data Quality and Community Dynamics in Wikidata
host: soton
start-date: 2015-04-13
supervisors:
  - Elena Simperl
publications:
  - Piscopo2017
---

Knowledge Graphs (KGs) are large collections of entities, their descriptions and relationships between them. KGs are a vital resource for QA systems, as they can be processed and aggregated to effectively construct comprehensive answers. Collectively created KGs exploit the “wisdom of the crowd” to produce and maintain high-quality and up-to-date information. In this context, an ongoing project that attracted significant community interest is Wikidata, from the Wikimedia foundation. Since its inception in October 2012, Wikidata has grown to include more than hundred thousand registered users. These users have already gathered the facts about more than 15 M entities and help maintaining the Wikidata KG to keep the representation of these entities and facts up-to-date. All the information in Wikidata is released under an open license, which allows the data to be freely reused and shared, offering a variety of opportunities to build knowledge-based systems on top of it. Rich up-to-date information regarding millions of entities within the Wikidata KG makes Wikidata particularly suitable as a knowledge resource for QA systems. In order to enable effective use of Wikidata in these systems, it is crucial to better understand the processes through which the Wikidata community produces knowledge. These understandings can provide valuable insights in the data quality in Wikidata and uncover hidden relationships between entities to support serendipitous information discovery in the QA processes. In particular, my aims are: First, I aim to investigate the relationship between the Wikidata community processes and their impact on the data quality. Second, I aim to verify whether these processes can be leveraged to provide serendipitous answers in QA systems. 

As a first step, I carried out research on the effects of a particular Wikidata feature, the lack of enforced property constraints, on the presence of conflicts and the expression of knowledge diversity. The results showed that, although the current level of conflictuality and knowledge diversity in Wikidata are low, they cannot be clearly connected to the feature analysed. Following that, I analysed how group features influence outcome quality. The findings showed that high quality Wikidata Items are edited by larger groups, with more diversely experienced editors than average. In these groups, a few editors carry out the bulk of the work, therefore implicitly coordinating the rest of the users. On the other hand, there was scarce evidence of active, explicit coordination by direct communication among users.
As a further step, during the secondment carried out at Wikimedia Germany, I created a draft of a data quality framework for Wikidata. The aim of this framework, grounded in previous findings on data quality, is to provide a theoretical understanding of the quality issues possibly affecting Wikidata and a base for a large-scale evaluation. I plan to evaluate two dimensions from this framework, due to their importance within Wikidata: reputation and consistency. The first one refers to “the extent to which sources specified for data are trustworthy”; its evaluation involves the assessment of the external references within Wikidata and will be carried out through crowdsourcing. The second dimension is related to the conceptual structure of Wikidata KG and will be evaluated by aligning it to the foundational ontology DOLCE.
Subsequently, I will conduct a study to explore how connections can be made between Wikidata entities on the basis of community processes, and how these connections can be exploited to provide serendipitous answers in a QA system. Finally, my project will be concluded by a user study to assess the relevancy and accurateness of the answers provided using this system.

Wikidata has raised signifcant interest among researchers and practitioners, due to some of its prominent features, such as openness, broad coverage, and a large user pool. In spite of the growing body of research about Wikidata, only few studies have focused on the quality of its data and even less on how this is determined by the collaborative patterns within its community. Our work seeks to address this gap. First, we perform an evaluation of some dimensions data quality in Wikidata, namely those related to its external references and to the consistency of its conceptual knowledge. Second, we analyse how editing patterns, specifcally the composition of group of users, determine some aspects of its quality. The results obtained so far highlight a high level of quality of external sources used in Wikidata, in terms of relevance and authoritativeness. Moreover, for what concerns community dynamics, our fndings show that a balanced contribution of human and bot users is benefcial for Wikidata quality.

